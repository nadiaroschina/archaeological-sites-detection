{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d192312-c28b-4d72-9bde-f52f5f3a61ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929fa1c-7a0b-45f2-828b-d2f002caade6",
   "metadata": {},
   "source": [
    "## Данные и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df28da3-1a4b-48cf-b11f-0438e055edc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import ArchDataset, GT_NEGATIVE_PATHS, GT_POSITIVE_PATHS, GT_NEGATIVE_COORDS, GT_POSITIVE_COORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ff7b3-30d1-4716-ad07-8262ded43499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import VQVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dafde4-237f-4b74-a299-afb345942e25",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Параметры модели и обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f4d68-bdca-4181-aa62-fe29b4685e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8814b-e41d-42f8-a335-3641e44911fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = 'v5'\n",
    "checkpoint_path = f'{results_dir}/checkpoint_14.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f15cc-4f1b-4e34-acce-3c9f9e317d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 512,\n",
    "    'img_size': 64,\n",
    "    'channels': 3,\n",
    "    'embedding_dim': 64,\n",
    "    'num_embeddings': 128,\n",
    "    'beta': 0.25,\n",
    "    'n_epochs': 15,  # 10\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6232a7d7-df6c-45e2-9c88-2d772194e67d",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdc949-0d1e-4b73-a40b-8de1941eacd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_crop_64 = transforms.Compose([\n",
    "    transforms.CenterCrop((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97664d61-df89-41b6-b398-961a23072187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ArchDataset(\n",
    "    img_paths=GT_NEGATIVE_PATHS, \n",
    "    coords=GT_NEGATIVE_COORDS, \n",
    "    anomalies=False, \n",
    "    transform=transform_crop_64\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "anomalies_dataset = ArchDataset(\n",
    "    img_paths=GT_POSITIVE_PATHS, \n",
    "    coords=GT_POSITIVE_COORDS, \n",
    "    anomalies=False, \n",
    "    transform=transform_crop_64\n",
    ")\n",
    "anomalies_loader = DataLoader(anomalies_dataset, batch_size=params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e7a86-873c-4aea-996b-85bb719bc4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'train: {len(train_dataset)} images, {len(train_loader)} batches')\n",
    "print(f'anomalies: {len(anomalies_dataset)} images, {len(anomalies_loader)} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ba0c1-d3c2-4ee0-997a-d82fe566d539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncols = 6\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=ncols, figsize=(16, 8))\n",
    "for i in range(ncols):\n",
    "    axs[0, i].axis('off')\n",
    "    axs[1, i].axis('off')\n",
    "    axs[0, i].imshow((anomalies_dataset[i][0].permute(1, 2, 0) + 1) / 2)\n",
    "    axs[1, i].imshow((train_dataset[i][0].permute(1, 2, 0) + 1) / 2)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9045dd-a8b1-478d-930a-ce167fd6d1a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9315cea-ebc2-4e8f-bd9d-49f7f5276c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VQVAE(\n",
    "    in_channels=params['channels'],\n",
    "    img_size=params['img_size'],\n",
    "    \n",
    "    embedding_dim=params['embedding_dim'],\n",
    "    num_embeddings=params['num_embeddings'],\n",
    "    beta=params['beta']\n",
    ")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1ba59-000e-4c6c-a2e0-1ddbc00044d6",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088924-deef-45e8-a4a4-c82f045d8404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lpips\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "vit_model = vit_b_16(weights=weights)\n",
    "vit_model.to(device)\n",
    "\n",
    "vit_model.heads = torch.nn.Identity()\n",
    "vit_model.eval();\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21fb37-e648-4576-9968-d032e69882b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(names):\n",
    "    imgs = []\n",
    "    for name in names:\n",
    "        img = transform_crop_64_grayscale(Image.open(name).convert('RGB'))\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def align_image(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "def draw_image(imgs):\n",
    "    fig, axes = plt.subplots(ncols=len(imgs) , figsize=(len(imgs) * 2, 2))\n",
    "\n",
    "    if len(imgs) == 1:\n",
    "        img = imgs[0]\n",
    "        cmap = 'gray' if img.shape[0] == 1 else None\n",
    "        axes.imshow(align_image(img).permute(1, 2, 0), cmap=cmap)\n",
    "    else:\n",
    "        for i, img in enumerate(imgs):\n",
    "            cmap = 'gray' if img.shape[0] == 1 else None\n",
    "            axes[i].imshow(align_image(img).permute(1, 2, 0), cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e98383-fc83-44e9-a016-49d562a0c141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vit_cosine_similarity(img1, img2):\n",
    "\n",
    "    assert len(img1.shape) == len(img2.shape) == 3,\\\n",
    "        f'expected images of shape C x W x H, got {img1.shape=} {img2.shape=}'\n",
    "\n",
    "    assert img1.shape[0] == img2.shape[0],\\\n",
    "        f'different number of channels: {img1.shape[0]=} {img2.shape[0]=}'\n",
    "    \n",
    "\n",
    "    if img1.shape[0] == 1:  # grayscale\n",
    "        img1 = img1.repeat(3, 1, 1)\n",
    "        img2 = img2.repeat(3, 1, 1)\n",
    "\n",
    "    resize = transforms.Resize(size=224, antialias=True)\n",
    "\n",
    "    img1 = resize(img1.unsqueeze(0))\n",
    "    img2 = resize(img2.unsqueeze(0))\n",
    "\n",
    "    features1 = vit_model(img1).cpu().detach().numpy()\n",
    "    features2 = vit_model(img2).cpu().detach().numpy()\n",
    "\n",
    "    sim = cosine_similarity(features1, features2)\n",
    "    return sim[0, 0].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52c418-9357-4554-8076-4b04a18eab83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(real_img, return_img=False):\n",
    "    \n",
    "    real_img_cuda = real_img.to(device)\n",
    "    reconstructed_img_cuda = model(real_img_cuda[None, :])[0][0]\n",
    "\n",
    "    sim = vit_cosine_similarity(real_img_cuda, reconstructed_img_cuda)\n",
    "    \n",
    "    if return_img:\n",
    "        return sim, reconstructed_img\n",
    "    else:\n",
    "        return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b4b1d-417a-4253-b003-f7e23d14ba7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomaly_dataset_scores = []\n",
    "for img, idx, coords, anomaly_flag in tqdm(anomalies_dataset, total=len(anomalies_dataset)):\n",
    "    sim = test(img)\n",
    "    anomaly_dataset_scores.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442aa10d-ff81-41a5-bf26-26d167477833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_scores = []\n",
    "for img, idx, coords, anomaly_flag in tqdm(train_dataset, total=len(train_dataset)):\n",
    "    sim = test(img)\n",
    "    train_dataset_scores.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc43fa-026d-4700-a0a1-584e5e78e2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(anomaly_dataset_scores, bins=20, color='lightcoral', alpha=0.7)\n",
    "plt.hist(train_dataset_scores, bins=20, color='royalblue', alpha=0.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7f517-3ab5-407f-bf46-5ebd284feae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomaly_dataset_scores = np.array(anomaly_dataset_scores)\n",
    "train_dataset_scores = np.array(train_dataset_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295ad91-4b60-4296-929c-eacc18490982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomalies_sorted_idxs = np.argsort(anomaly_dataset_scores)\n",
    "nrows, ncols = 2, 6\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize = (3 * ncols, 3 * nrows))\n",
    "\n",
    "fig.suptitle('Anomalies dataset: most suspisious')\n",
    "\n",
    "for j in range(ncols):\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].grid('off')\n",
    "        \n",
    "    idx = anomalies_sorted_idxs[j]\n",
    "    img = anomalies_dataset[idx][0]\n",
    "    sim, reconstructed_img = test(img, return_img=True)\n",
    "\n",
    "    axs[0, j].imshow((img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    axs[1, j].imshow((reconstructed_img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    \n",
    "    axs[0, j].title.set_text(f'sim: {sim:.4f}')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5b035-3eb7-4f24-9ba3-a1618910b4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomalies_sorted_idxs = np.argsort(-anomaly_dataset_scores)\n",
    "nrows, ncols = 2, 6\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize = (3 * ncols, 3 * nrows))\n",
    "\n",
    "fig.suptitle('Anomalies dataset: least suspisious')\n",
    "\n",
    "for j in range(ncols):\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].grid('off')\n",
    "        \n",
    "    idx = anomalies_sorted_idxs[-(j + 1)]\n",
    "    img = anomalies_dataset[idx][0]\n",
    "    sim, reconstructed_img = test(img, return_img=True)\n",
    "\n",
    "    axs[0, j].imshow((img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    axs[1, j].imshow((reconstructed_img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    \n",
    "    axs[0, j].title.set_text(f'sim: {sim:.4f}')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e6417-260a-4f6e-a93d-c6cc89538853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sorted_idxs = np.argsort(train_dataset_scores)\n",
    "nrows, ncols = 2, 6\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize = (3 * ncols, 3 * nrows))\n",
    "\n",
    "fig.suptitle('Train dataset: most suspisious')\n",
    "\n",
    "for j in range(ncols):\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].grid('off')\n",
    "        \n",
    "    idx = train_sorted_idxs[j]\n",
    "    img = train_dataset[idx][0]\n",
    "    sim, reconstructed_img = test(img, return_img=True)\n",
    "\n",
    "    axs[0, j].imshow((img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    axs[1, j].imshow((reconstructed_img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    \n",
    "    axs[0, j].title.set_text(f'sim: {sim:.4f}')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f0e68-832c-4a63-9d76-cc1b16d4fbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sorted_idxs = np.argsort(train_dataset_scores)\n",
    "nrows, ncols = 2, 6\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize = (3 * ncols, 3 * nrows))\n",
    "\n",
    "fig.suptitle('Train dataset: least suspisious')\n",
    "\n",
    "for j in range(ncols):\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].grid('off')\n",
    "        \n",
    "    idx = train_sorted_idxs[-(j+1)]\n",
    "    img = train_dataset[idx][0]\n",
    "    sim, reconstructed_img = test(img, return_img=True)\n",
    "\n",
    "    axs[0, j].imshow((img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    axs[1, j].imshow((reconstructed_img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    \n",
    "    axs[0, j].title.set_text(f'sim: {sim:.4f}')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65443b3e-f224-4278-bb85-fdbd5aff2224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sorted_idxs = np.argsort(train_dataset_scores)\n",
    "nrows, ncols = 2, 100\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize = (3 * ncols, 3 * nrows))\n",
    "\n",
    "fig.suptitle('Train dataset: most suspisious')\n",
    "\n",
    "for j in range(ncols):\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].grid('off')\n",
    "        \n",
    "    idx = train_sorted_idxs[j]\n",
    "    img = train_dataset[idx][0]\n",
    "    sim, reconstructed_img = test(img, return_img=True)\n",
    "\n",
    "    axs[0, j].imshow((img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    axs[1, j].imshow((reconstructed_img.permute(1, 2, 0).detach().numpy() + 1) / 2)\n",
    "    \n",
    "    axs[0, j].title.set_text(f'sim: {sim:.4f}')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe142d-9587-4079-a711-d50ef92218b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
